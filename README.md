# Balrog - Modern LLM Interface Wrapper

ğŸ‰ **Balrog** is a modern Flask-based web interface for LLM APIs with integrated safety model filtering using Llama Guard.

## Features

- ğŸ›¡ï¸ **Safety First**: Every request and response is filtered through a safety model (Llama Guard)
- ğŸ¨ **Modern UI**: Beautiful, responsive web interface with real-time chat
- ğŸ”§ **Flexible API Support**: Works with OpenAI, Anthropic, and other compatible APIs
- ğŸ“± **Mobile Friendly**: Responsive design that works on all devices
- ğŸš€ **Easy Setup**: Simple CLI with comprehensive argument parsing
- ğŸ“Š **Health Monitoring**: Built-in health checks and status monitoring
- ğŸ’¾ **Session Management**: Maintains conversation history during sessions
- ğŸ”„ **Real-time Updates**: Live status indicators and notifications

## Quick Start

### Installation

1. **Clone or download** the project files
2. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

### Usage

Run Balrog with your API credentials:

```bash
python balrog.py \
  --api https://api.openai.com/v1 \
  --model gpt-3.5-turbo \
  --api-key your_openai_api_key \
  --safety-model meta-llama/Llama-Guard-7b \
  --port 5000
```

### Command Line Arguments

| Argument | Required | Description | Example |
|----------|----------|-------------|---------|
| `--api` | âœ… | LLM API base URL | `https://api.openai.com/v1` |
| `--model` | âœ… | Model name to use | `gpt-3.5-turbo`, `gpt-4`, `claude-3-sonnet-20240229` |
| `--api-key` | âœ… | API key for authentication | `sk-...` |
| `--safety-model` | âœ… | Safety model name | `meta-llama/Llama-Guard-7b` |
| `--port` | âŒ | Port to host on (default: 5000) | `8080` |
| `--debug` | âŒ | Enable debug mode | - |
| `--log-level` | âŒ | Set logging level | `DEBUG`, `INFO`, `WARNING`, `ERROR` |

## Configuration Examples

### OpenAI GPT-4
```bash
python balrog.py \
  --api https://api.openai.com/v1 \
  --model gpt-4 \
  --api-key sk-your_openai_key \
  --safety-model meta-llama/Llama-Guard-7b \
  --port 8080
```

### Anthropic Claude
```bash
python balrog.py \
  --api https://api.anthropic.com/v1 \
  --model claude-3-sonnet-20240229 \
  --api-key your_anthropic_key \
  --safety-model meta-llama/Llama-Guard-7b \
  --port 5000
```

### Local Model (Ollama)
```bash
python balrog.py \
  --api http://localhost:11434/v1 \
  --model llama2 \
  --api-key dummy_key \
  --safety-model meta-llama/Llama-Guard-7b \
  --port 3000
```

## Safety Model Integration

Balrog integrates with **Llama Guard** or compatible safety models to filter content:

### Input Filtering
- User messages are checked before being sent to the main LLM
- Unsafe content is blocked and classified
- User receives feedback about why content was filtered

### Output Filtering  
- LLM responses are checked before being shown to the user
- Unsafe responses are blocked and classified
- User is notified that the response was filtered

### Safety Model Setup

The safety model uses the same API endpoint and key as the main model. Popular configurations:

- **OpenAI with Llama Guard**: Use OpenAI API with `meta-llama/Llama-Guard-7b` (requires compatible provider)
- **Together AI**: Both main model and safety model through Together AI
- **Local**: Self-hosted models via Ollama or similar
- **Mixed Setup**: Main model from one provider, safety model available on same endpoint

### Supported Safety Models

- `meta-llama/Llama-Guard-7b` - Llama Guard 7B model
- `meta-llama/Llama-Guard-13b` - Llama Guard 13B model  
- `text-moderation-latest` - OpenAI's moderation model
- Custom safety models following the same interface

## Web Interface Features

### Modern Chat UI
- ğŸ’¬ Real-time messaging interface
- ğŸ¨ Beautiful gradient design with animations
- ğŸ“± Fully responsive for mobile devices
- âŒ¨ï¸ Keyboard shortcuts (`Ctrl+Enter` to send, `Ctrl+K` to focus input)

### Status Monitoring
- ğŸŸ¢ Online/Offline status indicators
- â±ï¸ Last activity timestamps
- ğŸ¥ Health check functionality
- ğŸ“Š Real-time connection status

### Conversation Management
- ğŸ—‘ï¸ Clear conversation history
- ğŸ’¾ Session-based message persistence
- ğŸ“¤ Export chat history (JSON format)
- ğŸ”„ Auto-scroll to latest messages

### Notifications
- ğŸ¯ Toast notifications for all actions
- âš ï¸ Safety filter alerts
- âœ… Success/error status updates
- ğŸ”” Real-time feedback

## API Endpoints

Balrog provides several REST API endpoints:

### `POST /api/chat`
Send a chat message with safety filtering
```json
{
  "message": "Hello, how are you?"
}
```

**Response (Success)**:
```json
{
  "message": "I'm doing well, thank you for asking!",
  "timestamp": "2024-01-15T10:30:00.000Z"
}
```

**Response (Filtered)**:
```json
{
  "error": "Content filtered by safety model",
  "classification": "Inappropriate content detected",
  "type": "input_filtered"
}
```

### `POST /api/clear`
Clear conversation history
```json
{
  "status": "cleared"
}
```

### `GET /api/health`
Check application health
```json
{
  "status": "healthy",
  "timestamp": "2024-01-15T10:30:00.000Z",
  "model": "gpt-3.5-turbo"
}
```

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web Browser   â”‚    â”‚    Flask App    â”‚    â”‚   Safety Model  â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚  (Llama Guard)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Modern UI     â”‚â—„â”€â”€â–ºâ”‚ â€¢ Route Handler â”‚â—„â”€â”€â–ºâ”‚ â€¢ Input Filter  â”‚
â”‚ â€¢ Real-time     â”‚    â”‚ â€¢ Session Mgmt  â”‚    â”‚ â€¢ Output Filter â”‚
â”‚ â€¢ Responsive    â”‚    â”‚ â€¢ Error Handlingâ”‚    â”‚ â€¢ Classificationâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   Main LLM API  â”‚
                       â”‚                 â”‚
                       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                       â”‚ â€¢ OpenAI GPT    â”‚
                       â”‚ â€¢ Anthropic     â”‚
                       â”‚ â€¢ Local Models  â”‚
                       â”‚ â€¢ Safety Models â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Security Features

- ğŸ›¡ï¸ **Input Validation**: All user inputs are validated and sanitized
- ğŸ” **API Key Protection**: API keys are never exposed to the frontend
- ğŸš« **Content Filtering**: Dual-layer safety filtering (input + output)
- ğŸ“ **Logging**: Comprehensive logging for security monitoring
- ğŸŒ **CORS Protection**: Proper CORS headers for API security

## Troubleshooting

### Common Issues

**Port Already in Use**
```bash
# Use a different port
python balrog.py --port 8080 [other arguments]
```

**API Connection Errors**
- Verify your API key is correct
- Check your internet connection
- Ensure the API endpoint URL is correct

**Safety Model Unavailable**
- Balrog defaults to allowing content if safety model fails
- Check safety model endpoint and API key
- Monitor logs for safety model errors

### Debug Mode
```bash
python balrog.py --debug --log-level DEBUG [other arguments]
```

### Logs
- All errors and activities are logged to console
- Use `--log-level DEBUG` for detailed troubleshooting
- Check browser console for frontend errors

## Development

### Project Structure
```
balrog/
â”œâ”€â”€ balrog.py              # Main application
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html        # Web interface template
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ style.css         # Modern UI styles
â”‚   â””â”€â”€ script.js         # Frontend JavaScript
â””â”€â”€ README.md             # This file
```

### Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## License

This project is open source. Feel free to use, modify, and distribute.

## Support

For issues, questions, or feature requests:
1. Check the troubleshooting section
2. Review the logs with debug mode
3. Create an issue with detailed information

---

**Balrog** - Because your conversations deserve both intelligence and safety. ğŸ‰ğŸ›¡ï¸